(function cssExample() {
  // Based on the specs in:
  // https://www.w3.org/TR/CSS21/grammar.html

  // A little mini DSL for easier lexer definition using xRegExp.
  var fragments = {}

  function FRAGMENT(name, def) {
    fragments[name] = XRegExp.build(def, fragments)
  }

  function MAKE_PATTERN(def, flags) {
    return XRegExp.build(def, fragments, flags)
  }

  // ----------------- Lexer -----------------
  var Lexer = chevrotain.Lexer;

  // A Little wrapper to save us the trouble of manually building the
  // array of cssTokens
  var cssTokens = [];
  var createToken = function () {
    var newToken = chevrotain.createToken.apply(null, arguments);
    cssTokens.push(newToken);
    return newToken;
  }

  // The order of fragments definitions is important
  FRAGMENT('nl', '\\n|\\r|\\f');
  FRAGMENT('h', '[0-9a-f]');
  FRAGMENT('nonascii', '[\\u0240-\\uffff]');
  FRAGMENT('unicode', '\\{{h}}{1,6}');
  FRAGMENT('escape', '{{unicode}}|\\\\[^\\r\\n\\f0-9a-f]');
  FRAGMENT('nmstart', '[_a-zA-Z]|{{nonascii}}|{{escape}}');
  FRAGMENT('nmchar', '[_a-zA-Z0-9-]|{{nonascii}}|{{escape}}');
  FRAGMENT('string1', '\\"([^\\n\\r\\f\\"]|\\{{nl}}|{{escape}})*\\"');
  FRAGMENT('string2', "\\'([^\\n\\r\\f\\']|\\{{nl}}|{{escape}})*\\'");
  FRAGMENT('comment', '\\/\\*[^*]*\\*+([^/*][^*]*\\*+)*\\/');
  FRAGMENT("name", "({{nmchar}})+");
  FRAGMENT("url", "([!#\\$%&*-~]|{{nonascii}}|{{escape}})*");
  FRAGMENT("spaces", "[ \\t\\r\\n\\f]+");
  FRAGMENT("ident", "-?{{nmstart}}{{nmchar}}*");
  FRAGMENT("num", "[0-9]+|[0-9]*\\.[0-9]+");

  var Whitespace = createToken({
    name: 'Whitespace',
    pattern: MAKE_PATTERN('{{spaces}}'),
    group: Lexer.SKIPPED,
    line_breaks: true
  });
  var Comment = createToken({
    name: 'Comment',
    pattern: /\/\*[^*]*\*+([^/*][^*]*\*+)*\//,
    // the W3C specs are are defined in a whitespace sensitive manner.
    // but this grammar is not
    // TODO: there is actually one place in the CSS grammar where whitespace is meaningful.
    group: Lexer.SKIPPED,
    line_breaks: true
  });

  // This group has to be defined BEFORE Ident as their prefix is a valid Ident
  var Uri = createToken({name: 'Uri', pattern: Lexer.NA});
  var UriString = createToken({
    name: 'UriString',
    pattern: MAKE_PATTERN('url\\((:?{{spaces}})?({{string1}}|{{string2}})(:?{{spaces}})?\\)')
  });
  var UriUrl = createToken({name: 'UriUrl', pattern: MAKE_PATTERN('url\\((:?{{spaces}})?{{url}}(:?{{spaces}})?\\)')});
  var Func = createToken({name: 'Func', pattern: MAKE_PATTERN('{{ident}}\\(')});
  // Ident must be before Minus
  var Ident = createToken({name: 'Ident', pattern: MAKE_PATTERN('{{ident}}')});

  var Cdo = createToken({name: 'Cdo', pattern: /<!--/});
  // Cdc must be before Minus
  var Cdc = createToken({name: 'Cdc', pattern: /-->/});
  var Includes = createToken({name: 'Includes', pattern: /~=/});
  var Dasmatch = createToken({name: 'Dasmatch', pattern: /\|=/});
  var Exclamation = createToken({name: 'Exclamation', pattern: /!/});
  var Dot = createToken({name: 'Dot', pattern: /\./});
  var LCurly = createToken({name: 'LCurly', pattern: /{/});
  var RCurly = createToken({name: 'RCurly', pattern: /}/});
  var LSquare = createToken({name: 'LSquare', pattern: /\[/});
  var RSquare = createToken({name: 'RSquare', pattern: /]/});
  var LParen = createToken({name: 'LParen', pattern: /\(/});
  var RParen = createToken({name: 'RParen', pattern: /\)/});
  var Comma = createToken({name: 'Comma', pattern: /,/});
  var Colon = createToken({name: 'Colon', pattern: /:/});
  var SemiColon = createToken({name: 'SemiColon', pattern: /;/});
  var Equals = createToken({name: 'Equals', pattern: /=/});
  var Star = createToken({name: 'Star', pattern: /\*/});
  var Plus = createToken({name: 'Plus', pattern: /\+/});
  var Minus = createToken({name: 'Minus', pattern: /-/});
  var GreaterThan = createToken({name: 'GreaterThan', pattern: />/});
  var Slash = createToken({name: 'Slash', pattern: /\//});

  var StringLiteral = createToken({name: 'StringLiteral', pattern: MAKE_PATTERN('{{string1}}|{{string2}}')});
  var Hash = createToken({name: 'Hash', pattern: MAKE_PATTERN('#{{name}}')});

  // note that the spec defines import as : @{I}{M}{P}{O}{R}{T}
  // Where every letter is defined in this pattern:
  // i|\\0{0,4}(49|69)(\r\n|[ \t\r\n\f])?|\\i
  // Lets count the number of ways to write the letter 'i'
  // i // 2 options due to case insensitivity
  // |
  // \\0{0,4} // 5 options for number of spaces
  // (49|69) // 2 options for asci value
  // (\r\n|[ \t\r\n\f])? // 7 options, so the total for this alternative is 5 * 2 * 7 = 70 (!!!)
  // |
  // \\i // 1 option.
  // so there are a total of 73 options to write the letter 'i'
  // This gives us 73^6 options to write the word "import" which is a number with 12 digits...
  // This implementation does not bother with this crap :) and instead settles for
  // "just" 64 option to write "impPorT" (case due to case insensitivity)
  var ImportSym = createToken({name: 'ImportSym', pattern: /@import/i});
  var PageSym = createToken({name: 'PageSym', pattern: /@page/i});
  var MediaSym = createToken({name: 'MediaSym', pattern: /@media/i});
  var CharsetSym = createToken({name: 'CharsetSym', pattern: /@charset/i});
  var ImportantSym = createToken({name: 'ImportantSym', pattern: /important/i});


  var Ems = createToken({name: 'Ems', pattern: MAKE_PATTERN('{{num}}em', 'i')});
  var Exs = createToken({name: 'Exs', pattern: MAKE_PATTERN('{{num}}ex', 'i')});

  var Length = createToken({name: 'Length', pattern: Lexer.NA});
  var Px = createToken({name: 'Px', pattern: MAKE_PATTERN('{{num}}px', 'i'), parent: Length});
  var Cm = createToken({name: 'Cm', pattern: MAKE_PATTERN('{{num}}cm', 'i'), parent: Length});
  var Mm = createToken({name: 'Mm', pattern: MAKE_PATTERN('{{num}}mm', 'i'), parent: Length});
  var In = createToken({name: 'In', pattern: MAKE_PATTERN('{{num}}in', 'i'), parent: Length});
  var Pt = createToken({name: 'Pt', pattern: MAKE_PATTERN('{{num}}pt', 'i'), parent: Length});
  var Pc = createToken({name: 'Pc', pattern: MAKE_PATTERN('{{num}}pc', 'i'), parent: Length});

  var Angle = createToken({name: 'Angle', pattern: Lexer.NA});
  var Deg = createToken({name: 'Deg', pattern: MAKE_PATTERN('{{num}}deg', 'i'), parent: Angle});
  var Rad = createToken({name: 'Rad', pattern: MAKE_PATTERN('{{num}}rad', 'i'), parent: Angle});
  var Grad = createToken({name: 'Grad', pattern: MAKE_PATTERN('{{num}}grad', 'i'), parent: Angle});

  var Time = createToken({name: 'Time', pattern: Lexer.NA});
  var Ms = createToken({name: 'Ms', pattern: MAKE_PATTERN('{{num}}ms', 'i'), parent: Time});
  var Sec = createToken({name: 'Sec', pattern: MAKE_PATTERN('{{num}}sec', 'i'), parent: Time});

  var Freq = createToken({name: 'Freq', pattern: Lexer.NA});
  var Hz = createToken({name: 'Hz', pattern: MAKE_PATTERN('{{num}}hz', 'i'), parent: Freq});
  var Khz = createToken({name: 'Khz', pattern: MAKE_PATTERN('{{num}}khz', 'i'), parent: Freq});

  var Percentage = createToken({name: 'Percentage', pattern: MAKE_PATTERN('{{num}}%', 'i')});

  // Num must appear after all the num forms with a suffix
  var Num = createToken({name: 'Num', pattern: MAKE_PATTERN('{{num}}')});


  var CssLexer = new Lexer(cssTokens, {
    // Less position info tracked, reduces verbosity of the playground output.
    positionTracking:"onlyStart",
    // Adds tokenClassName property to the output for easier debugging in the playground
    // Do not use this flag in a productive env, as it will hurt performance.
    debug: true
  });

  // ----------------- parser -----------------
  var Parser = chevrotain.Parser;

  function CssParser(input) {
    Parser.call(this, input, cssTokens,
      {recoveryEnabled: true, maxLookahead: 3});
    var $ = this;

	sym stylesheet

		?
			ref charsetHeader

		// [S|CDO|CDC]*
		ref cdcCdo

		// [ import [ CDO S* | CDC S* ]* ]*
		* 
			ref cssImport
			ref cdcCdo

		// [ [ ruleset | media | page ] [ CDO S* | CDC S* ]* ]*
		*           $$ MANY2
			ref contents

	sym charsetHeader
		tk @charset
		string
		tk ;

	e contents
		|
			ref ruleset
			ref media
			ref page
		ref cdcCdo SUBRULE3

    // factor out repeating pattern for cdc/cdo
    
	e cdcCdo
		*
			|
				tk <!--
				tk -->

    // IMPORT_SYM S*
    // [STRING|URI] S* media_list? ';' S*
    
	sym cssImport
		tk @import
		|
			string
			uri
		?
			ref media_list
		tk ;

    // MEDIA_SYM S* media_list '{' S* ruleset* '}' S*
    
	sym media
		tk @media
		ref media_list
		tk {
		ref ruleset
		tk }

    // medium [ COMMA S* medium]*
    
	e media_list
		* ,
			ref medium

    // IDENT S*
    sym medium
		identifier

    // PAGE_SYM S* pseudo_page?
    // '{' S* declaration? [ ';' S* declaration? ]* '}' S*
    
	sym page
		tk @page
		?
			ref pseudo_page
		ref declarationsGroup

    // '{' S* declaration? [ ';' S* declaration? ]* '}' S*
    // factored out repeating grammar pattern
    
	sym declarationsGroup
		tk {
		?
			ref declaration
		*
			tk ;
			ref declaration
		tk }


    // ':' IDENT S*
    
	sym pseudo_page
		tk :
		identifier

    // '/' S* | ',' S*
    
	sym operator
		|
			tk /
			tk ,

    // '+' S* | '>' S*
    
	sym combinator
		|
			tk +
			tk >

    // '-' | '+'
    
	e unary_operator
		|
			tk -
			tk +

    // IDENT S*
    $.RULE('property', function () {
      $.CONSUME(Ident)
    });

    // selector [ ',' S* selector ]*
    // '{' S* declaration? [ ';' S* declaration? ]* '}' S*
    
	sym ruleset
		|
			* ,  $$ MANY_SEP COMMA
				ref selector
			ref declarationsGroup

    // simple_selector [ combinator selector | S+ [ combinator? selector ]? ]?
    
	sym selector
		ref simple_selector
		?
			?
				ref combinator
			ref selector

    // element_name [ HASH | class | attrib | pseudo ]*
    // | [ HASH | class | attrib | pseudo ]+
    
	e simple_selector
		|
			[
				ref element_name
				*
					ref simple_selector_suffix
			+
				ref simple_selector_suffix

    // helper grammar rule to avoid repetition
    // [ HASH | class | attrib | pseudo ]+
    
	e simple_selector_suffix
		|
			ref Hash
			ref class
			ref attrib
			ref pseudo

    // '.' IDENT
    
	sym class
		tk .
		identifier

	sym element_name
		|
			identifier
			lit *

    // '[' S* IDENT S* [ [ '=' | INCLUDES | DASHMATCH ] S* [ IDENT | STRING ] S* ]? ']'
    
	sym attrib
		tk [
		identifier
		?
			|
				lit =
				lit ~=
				lit |=
			|
				identifier $$ CONSUME2 ???
				string
		tk ]


    // ':' [ IDENT | FUNCTION S* [IDENT S*]? ')' ]
    sym pseudo
		tk :
		|
			identifier
			ref pseudoFunction

    sym pseudoFunction
		identifier
		tk (
			?
				identifier
		tk )

	// property ':' S* expr prio?
	sym declaration
		ref property
		tk :
		ref expression
		?
			ref prio

    // IMPORTANT_SYM S*
    sym prio
		lit important

    // term [ operator? term ]*
    e expression
		ref term
		*
			ref operator
			ref term

    // unary_operator?
    // [ NUMBER S* | PERCENTAGE S* | LENGTH S* | EMS S* | EXS S* | ANGLE S* |
    // TIME S* | FREQ S* ]
    // | STRING S* | IDENT S* | URI S* | hexcolor | function

	e term
		?
			ref unary_operator
		|
			ref Num
			ref Percentage
			ref Length
			ref Ems
			ref Exs
			ref Angle
			ref Time
			ref Freq
			ref StringLiteral
			identifier
			ref Uri
			ref hexcolor
			ref cssFunction

	sym CssFunction
		identifier
		tk (
		ref expression
		tk )

	sym hexcolor
		&
			tk #
			hex-char {6,8}


    // very important to call this after all the rules have been setup.
    // otherwise the parser may not work correctly as it will lack information
    // derived from the self analysis.
    Parser.performSelfAnalysis(this);
  }

  CssParser.prototype = Object.create(Parser.prototype);
  CssParser.prototype.constructor = CssParser;

  // for the playground to work the returned object must contain these fields
  return {
    lexer: CssLexer,
    parser: CssParser,
    defaultRule: "stylesheet"
  };
}())